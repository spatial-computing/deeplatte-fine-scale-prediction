{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from importlib import reload\n",
    "\n",
    "from models import dapm\n",
    "from scripts.data_loader import *\n",
    "from scripts.train_dapm import train\n",
    "from utils.metrics import normalize_mat\n",
    "from params import Param\n",
    "from utils.logging_utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.conv_lstm import ConvLSTM\n",
    "from models.fc import FC\n",
    "from models.auto_encoder import AutoEncoder\n",
    "from models.mask_net import MaskNet\n",
    "from models.feature_attention import FeatureAttention\n",
    "\n",
    "\n",
    "class DeepConvLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, ae_en_h_dims, ae_de_h_dims,\n",
    "                 conv_lstm_in_size, conv_lstm_in_dim, conv_lstm_h_dim, conv_lstm_kernel_sizes, conv_lstm_n_layers,\n",
    "                 fc_in_dim, fc_h_dims, fc_out_dim, **kwargs):\n",
    "\n",
    "        super(DeepConvLSTM, self).__init__()\n",
    "\n",
    "        self.kwargs = kwargs\n",
    "        self.device = kwargs.get('device', 'cpu')\n",
    "\n",
    "        ######################\n",
    "        # auto_encoder layer #\n",
    "        ######################\n",
    "\n",
    "        self.ae = AutoEncoder(in_dim=in_dim,\n",
    "                              en_h_dims=ae_en_h_dims,\n",
    "                              de_h_dims=ae_de_h_dims)\n",
    "\n",
    "        if kwargs.get('ae_pretrain_weight') is not None:\n",
    "            self.ae.load_state_dict(kwargs['ae_pretrain_weight'])\n",
    "        else:\n",
    "            raise ValueError('AutoEncoder not pretrained.')\n",
    "\n",
    "        for p in self.ae.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        ####################\n",
    "        # conv_lstm layers #\n",
    "        ####################\n",
    "\n",
    "        self.conv_lstm_list = nn.ModuleList()\n",
    "        for i in conv_lstm_kernel_sizes:\n",
    "            i_kernel_size = (i, i)\n",
    "            conv_lstm = ConvLSTM(in_size=conv_lstm_in_size,\n",
    "                                 in_dim=conv_lstm_in_dim,\n",
    "                                 h_dim=conv_lstm_h_dim,\n",
    "                                 kernel_size=i_kernel_size,\n",
    "                                 num_layers=conv_lstm_n_layers,\n",
    "                                 batch_first=kwargs.get('conv_lstm_batch_first', True),\n",
    "                                 bias=kwargs.get('conv_lstm_bias', True),\n",
    "                                 only_last_state=kwargs.get('only_last_state', True),\n",
    "                                 device=self.device)\n",
    "            self.conv_lstm_list.append(conv_lstm)\n",
    "\n",
    "        #########################\n",
    "        # fully-connected layer #\n",
    "        #########################\n",
    "\n",
    "        self.fc = FC(in_dim=fc_in_dim,  # assert in_dim == n_conv_lstm * conv_lstm_h_dim\n",
    "                     h_dims=fc_h_dims,\n",
    "                     out_dim=fc_out_dim,\n",
    "                     p_dropout=kwargs.get('fc_p_dropout', 0.1))\n",
    "\n",
    "    def forward(self, input_data):  # input_data: (b, t, c, h, w)\n",
    "\n",
    "        x = input_data.permute(0, 1, 3, 4, 2)  # => (b, t, h, w, c)\n",
    "\n",
    "        ######################\n",
    "        # auto-encoder layer #\n",
    "        ######################\n",
    "\n",
    "        en_x, de_x = self.ae(x)  \n",
    "        de_x = de_x.permute(0, 1, 4, 2, 3)  # => (b, t, c, h, w)\n",
    "        en_x = en_x.permute(0, 1, 4, 2, 3)  # => (b, t, c, h, w)\n",
    "\n",
    "        ####################\n",
    "        # conv_lstm layers #\n",
    "        ####################\n",
    "\n",
    "        conv_lstm_out_list = []\n",
    "        for conv_lstm in self.conv_lstm_list:\n",
    "            conv_lstm_last_hidden, conv_lstm_last_state = conv_lstm(en_x)\n",
    "            _, cell_last_state = conv_lstm_last_state\n",
    "            conv_lstm_out_list.append(cell_last_state)\n",
    "\n",
    "        conv_lstm_out = torch.cat(conv_lstm_out_list, dim=1)  # => (b, c, h, w)\n",
    "\n",
    "        #########################\n",
    "        # fully-connected layer #\n",
    "        #########################\n",
    "\n",
    "        fc_out = conv_lstm_out.permute(0, 2, 3, 1)  # => (b, h, w, c)\n",
    "        fc_out = self.fc(fc_out)\n",
    "        fc_out = fc_out.permute(0, 3, 1, 2)  # => (b, c, h, w)\n",
    "\n",
    "        return fc_out, en_x, de_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as dat\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from utils.early_stopping import EarlyStopping\n",
    "from utils.metrics import compute_error\n",
    "from models.spatial_loss_func import SpatialLossFunc\n",
    "\n",
    "\n",
    "def train(dapm, data_obj, args, **kwargs):\n",
    "    \n",
    "    \"\"\" construct index-based data loader \"\"\"\n",
    "    idx = np.array([i for i in range(args.seq_len, data_obj.train_y.shape[0])])\n",
    "    idx_dat = dat.TensorDataset(torch.tensor(idx, dtype=torch.int32))\n",
    "    train_idx_data_loader = dat.DataLoader(dataset=idx_dat, batch_size=args.batch_size, shuffle=True)\n",
    "    \n",
    "    idx = np.array([i for i in range(args.seq_len, data_obj.test_y.shape[0])])\n",
    "    idx_dat = dat.TensorDataset(torch.tensor(idx, dtype=torch.int32))\n",
    "    test_idx_data_loader = dat.DataLoader(dataset=idx_dat, batch_size=1, shuffle=False)\n",
    "\n",
    "    \"\"\" set writer, loss function, and optimizer \"\"\"\n",
    "    writer = SummaryWriter(kwargs['run_file'])\n",
    "    loss_func = nn.MSELoss()\n",
    "    spatial_loss_func = SpatialLossFunc(sp_neighbor=args.sp_neighbor) \n",
    "    optimizer = optim.Adam(dapm.parameters(), lr=args.lr, weight_decay=1e-8)\n",
    "#     scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.1, last_epoch=4000)\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        dapm.train()\n",
    "        total_losses, train_losses, val_losses = [], [], []\n",
    "\n",
    "        for _, idx in enumerate(train_idx_data_loader):\n",
    "            batch_idx = idx[0]\n",
    "\n",
    "            ############################\n",
    "            # construct sequence input #\n",
    "            ############################\n",
    "\n",
    "            def construct_sequence_x(idx_list, dynamic_x, static_x):\n",
    "                d_x = [dynamic_x[i - args.seq_len: i + 1, ...] for i in idx_list]\n",
    "                d_x = np.stack(d_x, axis=0)\n",
    "                s_x = np.expand_dims(static_x, axis=0)\n",
    "                s_x = np.repeat(s_x, args.seq_len + 1, axis=1)  # (t, c, h, w)\n",
    "                s_x = np.repeat(s_x, len(idx_list), axis=0)  # (b, t, c, h, w)\n",
    "                x = np.concatenate([d_x, s_x], axis=2)\n",
    "                return torch.tensor(x, dtype=torch.float).to(kwargs['device'])\n",
    "\n",
    "            def construct_y(idx_list, output_y):\n",
    "                y = [output_y[i] for i in idx_list]\n",
    "                y = np.stack(y, axis=0)\n",
    "                return torch.tensor(y, dtype=torch.float).to(kwargs['device'])\n",
    "\n",
    "\n",
    "            batch_x = construct_sequence_x(batch_idx, data_obj.dynamic_x, data_obj.static_x)  # x = (b, t, c, h, w)\n",
    "            batch_y = construct_y(batch_idx, data_obj.train_y)  # y = (b, c, h, w)\n",
    "            batch_val_y = construct_y(batch_idx, data_obj.val_y)\n",
    "\n",
    "            ###################\n",
    "            # train the model #\n",
    "            ###################\n",
    "\n",
    "            out, _, de_x = dapm(batch_x)\n",
    "            train_loss = loss_func(batch_y[~torch.isnan(batch_y)], out[~torch.isnan(batch_y)])\n",
    "            train_losses.append(train_loss.item())\n",
    "\n",
    "            # add loss according to the model type\n",
    "            total_loss = train_loss\n",
    "            \n",
    "            if 'ae' in args.model_type:\n",
    "                ae_loss = loss_func(batch_x, de_x)\n",
    "                total_loss += ae_loss * args.gamma\n",
    "                \n",
    "            total_losses.append(total_loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ######################\n",
    "            # validate the model #\n",
    "            ######################\n",
    "\n",
    "            val_loss = loss_func(batch_val_y[~torch.isnan(batch_val_y)], out[~torch.isnan(batch_val_y)])\n",
    "            val_losses.append(val_loss.item())\n",
    "        \n",
    "\n",
    "        avg_total_loss = np.average(total_losses)\n",
    "        avg_train_loss = np.average(train_losses)\n",
    "        avg_val_loss = np.average(val_losses)\n",
    "\n",
    "        # write for tensorboard visualization\n",
    "        writer.add_scalar('data/train_loss', avg_total_loss, epoch)\n",
    "        writer.add_scalar('data/val_loss', avg_val_loss, epoch)\n",
    "\n",
    "        logging.info(f'Epoch [{epoch}/{args.epochs}] total_loss = {avg_total_loss:.4f}, train_loss = {avg_train_loss:.4f}, valid_loss = {avg_val_loss:.4f}.')\n",
    "\n",
    "        ##################\n",
    "        # early_stopping #\n",
    "        ##################\n",
    "\n",
    "        early_stopping(avg_val_loss, dapm, kwargs['model_file'])\n",
    "\n",
    "        #########################\n",
    "        # evaluate testing data #\n",
    "        #########################\n",
    "        \n",
    "        if early_stopping.counter < 2 and epoch % 2 == 0:\n",
    "            \n",
    "            dapm.eval()\n",
    "            predictions = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(test_idx_data_loader):\n",
    "                    batch_idx = data[0]\n",
    "                    batch_x = construct_sequence_x(batch_idx, data_obj.dynamic_x, data_obj.static_x)  # x = (b, t, c, h, w)\n",
    "                    out, _, _ = dapm(batch_x)\n",
    "                    predictions.append(out.cpu().data.numpy())\n",
    "\n",
    "            prediction = np.concatenate(predictions)\n",
    "            rmse, mape, r2 = compute_error(data_obj.test_y[args.seq_len:, ...], prediction)\n",
    "            writer.add_scalar('data/test_rmse', rmse, epoch)\n",
    "            logging.info(f'Testing: RMSE = {rmse:.4f}, MAPE = {mape:.4f}, R2 = {r2:.4f}.')\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            logging.info(kwargs['model_name'] + f' val_loss = {early_stopping.val_loss_min:.4f}.')\n",
    "            logging.info('Early stopping')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dapm_main(param, **kwargs):\n",
    "    \n",
    "    \"\"\" define model name \"\"\" \n",
    "    model_name = param.generate_model_name()\n",
    "    ae_model_name = param.generate_ae_model_name()\n",
    "    print(model_name)\n",
    "    print(ae_model_name)\n",
    "\n",
    "    kwargs['model_name'] = model_name\n",
    "    kwargs['model_file'] = os.path.join(kwargs['model_dir'], model_name + '.pkl')\n",
    "    kwargs['log_file'] = os.path.join(kwargs['log_dir'], model_name + '.log')\n",
    "    kwargs['run_file'] = os.path.join(kwargs['run_dir'], model_name + '_run_{}'.format(datetime.datetime.now().strftime('%d%H%m')))\n",
    "    kwargs['ae_model_file'] = os.path.join('./data/ae_models_2/models/', ae_model_name + '.pkl')\n",
    "\n",
    "    \"\"\" load data \"\"\"\n",
    "    data_dir = f'/home/yijun/notebooks/training_data/'\n",
    "    data_obj = load_data(data_dir, param)\n",
    "    train_loc, val_loc, test_loc = load_locations(kwargs['train_val_test'], param)\n",
    "    \n",
    "    data_obj.train_loc = train_loc\n",
    "    data_obj.train_y = data_obj.gen_train_val_test_label(data_obj.label_mat, data_obj.train_loc)\n",
    "    data_obj.val_loc = val_loc\n",
    "    data_obj.val_y = data_obj.gen_train_val_test_label(data_obj.label_mat, data_obj.val_loc)\n",
    "    data_obj.test_loc = test_loc\n",
    "    data_obj.test_y = data_obj.gen_train_val_test_label(data_obj.label_mat, data_obj.test_loc)\n",
    "    \n",
    "    \"\"\" logging starts \"\"\"\n",
    "    start_logging(kwargs['log_file'], model_name)\n",
    "    data_logging(data_obj)\n",
    "\n",
    "    \"\"\" load ae model \"\"\"\n",
    "    ae = torch.load(kwargs['ae_model_file'])\n",
    "    \n",
    "    \"\"\" define DeepAP model\n",
    "    in_dim, ae_en_h_dims, ae_de_h_dims\n",
    "    conv_lstm_in_size, conv_lstm_in_dim, conv_lstm_h_dim, conv_lstm_kernel_sizes, conv_lstm_n_layers\n",
    "    fc_in_dim, fc_h_dims, fc_out_dim  \"\"\"\n",
    "    m = DeepConvLSTM(in_dim=data_obj.n_features,\n",
    "                     ae_en_h_dims=param.ae_en_h_dims,\n",
    "                     ae_de_h_dims=param.ae_de_h_dims,\n",
    "                         \n",
    "                     conv_lstm_in_size=(data_obj.n_rows, data_obj.n_cols),\n",
    "                     conv_lstm_in_dim=param.ae_en_h_dims[-1],  \n",
    "                     conv_lstm_h_dim=[param.dapm_h_dim],  # dap_h_dim\n",
    "                     conv_lstm_kernel_sizes=param.kernel_sizes,  # kernel_sizes\n",
    "                     conv_lstm_n_layers=1,\n",
    "\n",
    "                     fc_in_dim=param.dapm_h_dim * len(param.kernel_sizes),\n",
    "                     fc_h_dims=param.fc_h_dims,  # fc_h_dims\n",
    "                     fc_out_dim=1,\n",
    "\n",
    "                     ae_pretrain_weight=ae.state_dict(),\n",
    "                     mask_thre=param.mask_thre,\n",
    "                     fc_p_dropout=0.1,\n",
    "                     device=kwargs['device'])\n",
    "   \n",
    "    m = m.to(kwargs['device'])\n",
    "    train(m, data_obj, param, **kwargs)\n",
    "    \n",
    "    \"\"\" logging ends \"\"\"\n",
    "    end_logging(model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    define directory\n",
    "\"\"\"\n",
    "\n",
    "base_dir = f'data/deep_conv_lstm/'\n",
    "train_val_test_file = f'/home/yijun/notebooks/training_data/train_val_test_los_angeles_500m_fine_tune_1234.json'\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else 'cpu')  # the gpu device\n",
    "\n",
    "\"\"\" load train, val, test locations \"\"\"\n",
    "f = open(train_val_test_file, 'r')\n",
    "train_val_test = json.loads(f.read())\n",
    "\n",
    "kwargs = {\n",
    "    'model_dir': os.path.join(base_dir, 'models/'),\n",
    "    'log_dir': os.path.join(base_dir, 'logs/'),\n",
    "    'run_dir': os.path.join(base_dir, 'runs/'),\n",
    "    'train_val_test': train_val_test,\n",
    "    'device': device\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dapm___ae___los_angeles_500m_2018___#01#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#01#___16\n",
      "dapm___ae___los_angeles_500m_2018___#02#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#02#___16\n",
      "dapm___ae___los_angeles_500m_2018___#03#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#03#___16\n",
      "dapm___ae___los_angeles_500m_2018___#04#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#04#___16\n",
      "dapm___ae___los_angeles_500m_2018___#05#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#05#___16\n",
      "dapm___ae___los_angeles_500m_2018___#06#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#06#___16\n",
      "dapm___ae___los_angeles_500m_2018___#07#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#07#___16\n",
      "dapm___ae___los_angeles_500m_2018___#08#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#08#___16\n",
      "dapm___ae___los_angeles_500m_2018___#09#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#09#___16\n",
      "dapm___ae___los_angeles_500m_2018___#10#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#10#___16\n",
      "dapm___ae___los_angeles_500m_2018___#11#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#11#___16\n",
      "dapm___ae___los_angeles_500m_2018___#12#___6_00001_1___1_01_5_001___16_13\n",
      "ae___los_angeles_500m_2018___#12#___16\n"
     ]
    }
   ],
   "source": [
    "for m in range(1, 13):\n",
    "    param = Param([m], 2018, gamma=5, lr=0.001, model_type=['ae'])\n",
    "    dapm_main(param, **kwargs)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

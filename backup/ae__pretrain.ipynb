{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "from params import Param\n",
    "from models.auto_encoder import AutoEncoder\n",
    "from scripts.data_loader import *\n",
    "from scripts.pretrain_ae import train\n",
    "from utils.metrics import normalize_mat\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ae_main(param, **kwargs):\n",
    "    \n",
    "    model_name = param.generate_ae_model_name()\n",
    "    \n",
    "    kwargs['model_name'] = model_name\n",
    "    kwargs['model_file'] = os.path.join(model_dir, model_name + '.pkl')\n",
    "    kwargs['run_file'] = os.path.join(run_dir, model_name + '_run_{}'.format(datetime.datetime.now().strftime('%d%H%m')))\n",
    "    print(model_name)\n",
    "\n",
    "    \"\"\" load data \"\"\"\n",
    "    data_dir = f'/home/yijun/notebooks/training_data/'\n",
    "    data_obj = load_data(data_dir, param, if_retain_last_dim=False)\n",
    "   \n",
    "    \"\"\" define AutoEncoder model \"\"\"\n",
    "    ae = AutoEncoder(in_dim=data_obj.n_dynamic_features + data_obj.n_static_features,\n",
    "                     en_h_dims=param.ae_en_h_dims,\n",
    "                     de_h_dims=param.ae_de_h_dims).to(kwargs['device'])\n",
    "\n",
    "    train(ae, data_obj, param, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    define directory\n",
    "\"\"\"\n",
    "\n",
    "base_dir = './data/ae_models_2'\n",
    "model_dir = os.path.join(base_dir, 'models/')\n",
    "run_dir = os.path.join(base_dir, 'runs/')\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else 'cpu')  # the gpu device\n",
    "\n",
    "kwargs = dict()\n",
    "kwargs['model_dir'] = model_dir\n",
    "kwargs['run_dir'] = run_dir\n",
    "kwargs['device'] = device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae___los_angeles_500m_2018___#01#___16\n",
      ">>> ae___los_angeles_500m_2018___#01#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.6902674785319795.\n",
      "Epoch [5/20], Loss = 0.23694780247008546.\n",
      "Epoch [10/20], Loss = 0.22081387074703865.\n",
      "Epoch [15/20], Loss = 0.21531859832875272.\n",
      ">>> ae___los_angeles_500m_2018___#01#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#02#___16\n",
      ">>> ae___los_angeles_500m_2018___#02#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7300263061079868.\n",
      "Epoch [5/20], Loss = 0.24252895802952523.\n",
      "Epoch [10/20], Loss = 0.224686503756878.\n",
      "Epoch [15/20], Loss = 0.2174585950235988.\n",
      ">>> ae___los_angeles_500m_2018___#02#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#03#___16\n",
      ">>> ae___los_angeles_500m_2018___#03#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7335319455633772.\n",
      "Epoch [5/20], Loss = 0.2622073746107994.\n",
      "Epoch [10/20], Loss = 0.24589992457247795.\n",
      "Epoch [15/20], Loss = 0.23650272729549002.\n",
      ">>> ae___los_angeles_500m_2018___#03#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#04#___16\n",
      ">>> ae___los_angeles_500m_2018___#04#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7106000806974329.\n",
      "Epoch [5/20], Loss = 0.25543607609427493.\n",
      "Epoch [10/20], Loss = 0.23849356239256653.\n",
      "Epoch [15/20], Loss = 0.23003948188346365.\n",
      ">>> ae___los_angeles_500m_2018___#04#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#05#___16\n",
      ">>> ae___los_angeles_500m_2018___#05#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7121984844512128.\n",
      "Epoch [5/20], Loss = 0.25100470540371345.\n",
      "Epoch [10/20], Loss = 0.23522312717234833.\n",
      "Epoch [15/20], Loss = 0.22581891620412786.\n",
      ">>> ae___los_angeles_500m_2018___#05#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#06#___16\n",
      ">>> ae___los_angeles_500m_2018___#06#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7028261870145798.\n",
      "Epoch [5/20], Loss = 0.2537857527318208.\n",
      "Epoch [10/20], Loss = 0.23764643397020258.\n",
      "Epoch [15/20], Loss = 0.22829175222179163.\n",
      ">>> ae___los_angeles_500m_2018___#06#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#07#___16\n",
      ">>> ae___los_angeles_500m_2018___#07#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7080181019103273.\n",
      "Epoch [5/20], Loss = 0.2500138190832544.\n",
      "Epoch [10/20], Loss = 0.2366049736738205.\n",
      "Epoch [15/20], Loss = 0.2291568302093668.\n",
      ">>> ae___los_angeles_500m_2018___#07#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#08#___16\n",
      ">>> ae___los_angeles_500m_2018___#08#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7147986235770774.\n",
      "Epoch [5/20], Loss = 0.24449498285638524.\n",
      "Epoch [10/20], Loss = 0.22944003216763761.\n",
      "Epoch [15/20], Loss = 0.22395467884997103.\n",
      ">>> ae___los_angeles_500m_2018___#08#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#09#___16\n",
      ">>> ae___los_angeles_500m_2018___#09#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7232516621765883.\n",
      "Epoch [5/20], Loss = 0.25708984648403915.\n",
      "Epoch [10/20], Loss = 0.243952514036842.\n",
      "Epoch [15/20], Loss = 0.23631889113913412.\n",
      ">>> ae___los_angeles_500m_2018___#09#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#10#___16\n",
      ">>> ae___los_angeles_500m_2018___#10#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.6996318152610291.\n",
      "Epoch [5/20], Loss = 0.24282190108552892.\n",
      "Epoch [10/20], Loss = 0.22509761598516018.\n",
      "Epoch [15/20], Loss = 0.21817319982863487.\n",
      ">>> ae___los_angeles_500m_2018___#10#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#11#___16\n",
      ">>> ae___los_angeles_500m_2018___#11#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7093141169651694.\n",
      "Epoch [5/20], Loss = 0.26439501539520593.\n",
      "Epoch [10/20], Loss = 0.2474863587514214.\n",
      "Epoch [15/20], Loss = 0.2418476871174315.\n",
      ">>> ae___los_angeles_500m_2018___#11#___16 has been saved.\n",
      "ae___los_angeles_500m_2018___#12#___16\n",
      ">>> ae___los_angeles_500m_2018___#12#___16: Training process has started.\n",
      "Epoch [0/20], Loss = 0.7082917265435482.\n",
      "Epoch [5/20], Loss = 0.2700819287528383.\n",
      "Epoch [10/20], Loss = 0.2554120294591214.\n",
      "Epoch [15/20], Loss = 0.24886028246676667.\n",
      ">>> ae___los_angeles_500m_2018___#12#___16 has been saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for m in range(1, 13):    \n",
    "    param = Param(months=[m], year=2018, epochs=20, lr=0.01, batch_size=16, ae_en_h_dims=[64, 16], ae_de_h_dims=[16, 64])\n",
    "    ae_main(param, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
